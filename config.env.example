# Configuración del tipo de modelo a usar
# Opciones: 'openai', 'ollama', 'bedrock' (default)
MODEL_TYPE=openai

# Configuración de OpenAI
OPENAI_API_KEY=tu_api_key_aqui
OPENAI_MODEL_ID=gpt-3.5-turbo
OPENAI_MAX_TOKENS=1000
OPENAI_TEMPERATURE=0.7

# Configuración de Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL_ID=qwen3:1.7b
OLLAMA_TEMPERATURE=0.2
OLLAMA_KEEP_ALIVE=10m
OLLAMA_STOP_SEQUENCES=###,END
OLLAMA_TOP_K=40

# Configuración de AWS (para Bedrock)
# Las credenciales de AWS se configuran automáticamente desde:
# - Variables de entorno AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY
# - Archivo ~/.aws/credentials
# - IAM roles (en EC2, ECS, etc.)